# The world beyond batch: Streaming 102
 >原文作者：Tyler Akidau  
 >译者：    董捷

## 简介
欢迎回来！如果你错过了前一篇博文，The world beyond batch: Streaming 101，我强烈建议先花一点时间阅读第一篇博文。第一篇博文介绍了我接下来讲述的这篇博文的一些必要的基础，我假设本篇博文的读者已经熟悉了前一篇博文内介绍的名词与概念。

同时，请注意本篇博文里包含了许多动画，所以如果读者直接打印的话将丢失一些精华内容。

免责申明说完了，让Party开始吧！首先简单回顾一下，上次我专注在三个主要的领域：**名词**，精确地定义了我们常说的比如“流处理”的概念；**批处理与流处理对比**，比较这两种处理模式理论上的能力，并且提出了流计算若想超越批计算，仅需考虑两件事：1.正确性 2.推理时间的工具；和**数据处理模式**，探讨了批处理与流处理在处理有界与无界数据时的基本方法。

在这篇博文中，我希望在数据处理模式这个问题上更加深入，并且利用具体个案带场景更加更具体地深入挖掘。本篇博文的结构主要包括两部分：

* **温顾Streaming 101**: 简要回顾Streaming 101博文中阐述的概念，并通过具体例子阐述之前的观点。
* **Streaming 102**：Streaming 101的伴生篇，通过一系列具体案例，使之前介绍的概念更加具体易于理解。

当介绍完这篇博文时，我将覆盖我认为打造一个健壮的乱序数据处理系统的核心原则与理念；这就是推理时间的工具，这些工具使得流处理在真正意义上超越传统批处理。

为了更好地理解现实中这些工具的应用，我将使用Dataflow SDK（也就是Google Could Dataflow的API）的片段代码帮助阐述，辅以部分展示概念的动画。我使用Dataflow SDK而不是其他一些大家可能更熟悉的SDK，比如Spark Streaming或者Storm的理由是在今天没有其他系统的API在语义上能够表达我今天所要讲述的所有案例。好消息是其他系统正在往这个方向努力。一个更好的消息是我们（Google）如今给Apache Software Foundation提交了一个提案：创建一个Apache Dataflow孵化项目（联合包括data Artisans，Cloudera，Talend与一些其他公司），希望以Dataflow提供的健壮的无序处理语义为中心，创立一个开放的社区与生态。这将使得2016年成为一个非常有趣的年份，不好意思跑题了- -

本篇博文将不会探讨上次我承诺的流处理与批处理的对比；不好意思，我错误地低估了我想要在这篇博文中探讨的内容量与整理这些内容所需花费的时间。当下，我根本无法预估加入这个章节可能造成的延期。可能带来些许安慰的是，我最终在Strata+Hadoop 2015世界大会上分享了“海量数据处理的演化”这个议题（并可能在2016伦敦Strata+Hadoop世界大会上分享更新版），其中包含了许多我希望在对比环节中涵盖的内容。分享所使用的制作精美的幻灯片可以从[这里](http://goo.gl/5k0xaL)获得，请自行下载。可以肯定的是，幻灯片内容与原先承诺的对比章节会有所不同，但好歹凑合-  -

## 回顾与路线图
在Streaming 101中，我首先澄清了一些名词。首先区分了有界与无界数据。有界数据源拥有有限的大小，也就是通常我们所谓的“批”数据。无界数据源可能在大小上是无限的，也就是通常我们所谓的“流”数据。我尝试避免使用批数据与流数据，因为他们常常伴随特定的误导且受限的含义。

之后我定义了批处理与流处理引擎的区别：批处理引擎是那些在设计时仅考虑有界数据的引擎，而流处理引擎是设计时考虑无界数据的引擎。我的目标是仅在描述处理引擎时使用“批”与“流”这两个名词。

在名词解释之后，我涵盖了两个处理无界数据时非常重要而基本的概念。我首先提出了事件时间（事件发生的时间）与处理时间（事件对处理引擎可见的时间）关键的区别。这奠定了Streaming 101提出的一个重要观点的基石：如果你同时关心正确性与事件真正发生时间这个上下文，必须在事件真正发生的事件时间的角度上，而非数据被处理的处理时间的角度上分析数据。

之后，我介绍了**窗口化**（也就是以临时的边界区隔数据集）这个概念，这是个处理理论上可能无穷无尽的无界数据的普遍方法。一些简单的窗口包括固定窗口与滑动窗口，但是一些更加复杂的窗口，比方会话窗口（由数据本身特性定义的窗口，比方由一段用户睡眠时间作为区隔，获得用户活跃时间作为会话的窗口）也有广泛的用途。

除了这两个概念，我们将更深刻地探讨三个更多的概念：

* **Watermarks**：一个Watermark是一个事件时间之前的输入已经全部完成的标记。一个带有x时间戳的Watermark有以下含义：“在事件时间x之前的所有事件均已可见”，这样，Watermark扮演了观察不可预见结束的无界数据源时数据进展这个指标的角色。

* **Trigger**：一个触发器是一种申明根据外界信号导致窗口的输出需发送的机制。触发器提供了决定何时发送窗口输出的灵活性。同时提供了窗口在变化时数据多次可见的可能性。反过来看，触发器使得多次修正窗口内的数据成为可能，这提供了根据上游数据源变化修正推测结果的能力，同时也提供了处理迟到数据的能力（比如手机传感器，当用户里离线时，他们记录了手机各种各样的信息，而后当用户重新连线时把这些离线时收集的数据继续传送上报）。

* **Accumulation**：一种Accumulation模式指定了同一个窗口内多个数据记录的关系。这些记录可能完全不相关，也就是他们作为时间轴上完全独立增量，抑或他们之间可能重叠。不同的Accumulation模式拥有不同的语义与不同的成本，因此需要从多种使用案例中寻找合适的模式。

最后，因为我希望使得大家更容易理解这些概念的关联，我们将会利用以下4个问题温故知新，这些问题对于处理所有无界数据的场景都非常关键：

* **What** results are calculated？ 这个问题的答案是处理流水线中的各类变形函数。其中包括计算求和，构建直方图，训练机器学习模型等。同样在经典批处理中也是如此。
* **Where** in event time are results calculated？这个问题的答案是处理流水线中事件时间窗的使用。其中包括Streaming 101中介绍的常见的窗口（固定窗口、滑动窗口与会话窗口），一些似乎没有使用任何窗口的场景（比如Streaming 101中介绍的一些时间无关的处理场景，同时传统的批处理也归为此类），和一些更复杂的窗口，比如限时拍卖。同时请注意窗口也涵盖了处理时间窗，如果你把消息进入系统的时间作为事件时间的话。
* **When** in processing time are results materialized？这个问题的答案是结合Watermarks与Triggers的使用。这个主题可以有无数种变形，但是最常见的使用模式是利用Watermarks划分特定窗口的边界，同时使用Triggers允许在窗口数据完整之前（为了实时估算，部分数据在窗口内数据完整前便发送结果）或之后（在Watermark仅仅作为窗口完整的大致参考的场景下，更多数据输入可能在Watermark之后到达）。
* **How** do refinements of results relate？这个问题的答案是选用了哪种Accumulation：discarding（多个结果都是独立且不同的），accumulating（后期结果依赖前期结果）和retracting（accumulating的值外加回撤之前触发的值一起发出）

我们将在接下来的部分更深入具体地研究以上的问题。对，我会使用一些带有颜色的标签去尝试使得这些问题相对应的概念更加明确，不用谢XD。（*注：请忽略，译者懒得搞颜色）。

## Streaming 101温习
首先，让我们回顾一下在Streaming 101中介绍的概念。不过这次，我们将使用具体的例子使得这些概念更加具体。

What：transforms

在传统批处理中应用的变形函数解答了以下问题：“What results are calculated？”即便你们中的很多人可能对经典批处理已经非常熟悉，我们将会从批处理入手，毕竟它是我们如今新增的其他概念的基础。

在这部分，我们看一下这个例子：计算10个带有键值的整形数据(keyed integer)的sum值，以键值区分。如果你想要一个更具体的场景帮助理解，我们就举个例子：多组人玩一款手机游戏，我们要统计各组人获得的总分，我们需要将组内各个人的分数相加。你也可以想象类似地，计费与用量监控场景也是如此。

对于每个例子，我将使用Dataflow SDK的片段伪代码让处理流水线更加具体。所使用的都是伪代码，我会改变一些语法规则使得例子更清晰，同时我会省略一些详情（比方具体的I/O数据源），或简写一些类名（目前版本的Java SDK中Trigger的类名简直太啰嗦了，为了可读性我会简化它们）。除了这些小改动，它们基本上就是现实中的Dataflow SDK代码。同时，之后我也会提供感兴趣的用户可自行编译运行的真实代码。

如果你稍微了解Spark Streaming或者Flink，你将很容易看懂Dataflow的代码想要干什么。给你上一节快速强化课，Dataflow有两个基本元素：

* **PCollections**，它代表了数据集（有可能是超大的那种），在它之上，可以执行并发的变形函数（所以它名字前有个P）。
* **PTransforms**，它就是应用在PCollections之上从而产生新的PCollections。PTransforms可能是针对每个元素的变形，可能是多个数据的聚合，或者它可能是其他多个PTransforms的组合。

![transformers](https://d3ansictanv2wj.cloudfront.net/Figure-01---Transforms-daa8ad32f2995801b32dc2929f24d4ad.jpg)

如果你发现自己懵逼了，或者你想看看参考文献，可以参考[Dataflow Java SDK文档](https://cloud.google.com/dataflow/model/programming-model)。

回到例子的问题，我们假设我们从一个叫“input“的```PCollection<KV<String, Integer>>```开始，这里Strings就是团队名，Integer就是相应组内每个人的分数。现实中的流水线里，我们会从例如日志记录等原始数据中读取到一个```PCollection```，然后通过解析每条日志记录，把它转变为```PCollection<KV<String, Integer>>```。为了第一个例子的清晰性，我将会包括其他所有步骤的伪代码，但是在之后的例子中，我将会省略```I/O```读取与解析的部分。

如此，对于一个简单地读取单一```I/O源```的流水线，解析队名/分数对，然后计算各队的总分，我们的代码大致如下：

```javacode
PCollection<String> raw = IO.read(...);
PCollection<KV<String, Integer>> input = raw.apply(ParDo.of(new ParseFn());
PCollection<KV<String, Integer>> scores = input
  .apply(Sum.integersPerKey());
```
> Listing 1. 求和流水线. Key/value 从单一```I/O```源读取, String作为队名，Integer作为比分。各队的比分分别求和统计。


对于所有之后的例子，在看到对应我们将要分析的逻辑流水线的伪代码之后，我们会看到一个展示获取到正确的输入之后，流水线如何运作的动画。更精确地说，我们将看到一个10个相同键值的数值作为输入的流水线的具体流程。在真实的流水线中，你可以想象在分布式的多个节点上会并行地发生类似的操作，但是为了我们这个例子，我们让事情尽可能保持简单。

每一个动画描绘了两个维度上的输入与输出：事件时间（X轴）和处理时间（Y轴），这样，流水线进展中观测到的真实时间的流逝就是从底部到顶部，就像上升的粗白线标注的那样。输入是一个个圈，圈中的数字代表每个输入具体的数值。它们开始是灰色的并将会在流水线观测到它们时改变颜色。

当流水线观测到数值时，它会在自己的状态中聚积这些值，并最终发出汇聚之后的结果作为输出。状态与输出表现为矩形，并在矩形顶部附近标注了在对应事件时间和处理时间内汇聚的数值。对于Listing 1的流水线，当执行经典批量处理时，动画如下所示（注意，点击图片将开始执行动画，动画会一直重复播放直到再次点击图片）：

![batch]()

因为这是个批流水线，它将会聚积状态直到它看到所有的输入（如顶部的绿色虚线所示），那时，它产出了唯一的输出51。在这个例子里，因为我们并没有指定窗口，我们计算了所有事件时间内数据的总和。因此，表示状态和输出的矩形覆盖了整个X轴。如果我们希望处理一个无界的数据源，经典批处理将无能为力。我们不能等待所有数据都到位因为他们永远不会终结。于是我们会希望一个概念，也就是窗口化，也就是我们在Streaming 101中介绍的。因此，在第二个问题的上下文中：“Where in event-time are results calculated？”，我们简单回顾下窗口化。

Where：windowing

就像上次讨论的，窗口化就是把数据源根据临时边界切分为一个个的过程。通常切分窗口的策略包括固定窗口，滑动窗口与会话窗口：

![windows](https://d3ansictanv2wj.cloudfront.net/Figure-03---Windowing-442db0cda782c8bc0d8a2769423c6f37.jpg)

为了找一个更好的现实中窗口具体长什么样子的感觉，让我们讲我们整形累加流水线切分为固定的，2分钟滚动的窗口。用Dataflow SDK，仅仅稍微增加一个```Window.into```变形即可。

```javacode
PCollection<KV<String, Integer>> scores = input
  .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2))))
  .apply(Sum.integersPerKey());
```

请谨记，窗口对于批处理与流处理提供了统一抽象，因为语义上讲，批处理仅仅是流处理的一个子问题。就这样，让我们首先用批处理引擎执行这个流水线；这个机制更为简单粗暴，同时，当我们切换到流引擎后，它将会让我们能够直观地对比两者。

![windowing]()

就像之前那样，输入在状态中累积，直到他们被完全消费，之后将会产出输出结果。然而此时，对比之前1个结果，我们得到4个结果：每个2分钟的事件窗口都产出了一个输出。

此刻，我们回顾了Streaming 101中提出的两个主要的概念：事件时间与处理时间的关系，以及窗口化。如果我们想要更深入，我们需要加入本章节之前介绍的新概念：Watermarks，Triggers和Accumulation。在这里我们拉开了Streaming 102的篇章。

## Streaming 102

我们刚刚观察了批处理引擎中窗口化的处理流水线。但是理想中，我们同时希望我们的结果是低延时的，此外我们也希望我们能够处理无界的数据源。切换到流处理引擎是正确的一步，但是然而批处理引擎有一个事件窗口里所有输入都完整的时点（也就是当所有有界数据都被消费完的时候），我们目前缺少一个行之有效的方式决定无界数据的完整。于是我们有了Watermarks。

When：watermakrs

Watermarks是以下问题的前半个解答：“When in processing time are results materialized?”Watermarks是事件时间领域中输入完整的临时标志。换一个角度想，它们是系统衡量事件流中消息被处理的进度与完整性的指标（在有界与无界数据源中均是如此，只不过显然它们在无界数据源的场景中更为有用）。

回忆下Streaming 101中的一张图，这里稍微做了一些调整，图里我这么描述事件时间与处理时间间的偏移：对于大多数现实中的数据处理系统来说，它是一个不停变化的函数。

![skew](https://d3ansictanv2wj.cloudfront.net/Figure_05_-_Event_Time_vs_Processing_Time-6484c65e43d1821c617bee747b7de020.png)

那条曲折的红线在现实中本质上就是Watermark；它体现了随处理时间增长，事件时间完整性的增长。概念上，你可以把Watermark理解为一个函数，F(P)->E，拥有一个处理时间的参数，返回一个事件时间的结果。（更确切地讲，这个函数的输入其实是Watermark观察到时整个流水线中所有上游的当前状态：输入源，缓冲区的数据，正在被处理的数据等；但是概念上，我们可以把它简单地理解为处理时间到事件时间的映射。）那个事件时间的时点，E，就是系统认为所有在事件时间之前发生的事件都已经可见的时点。换句话说，这是个假设：再也不会有在E之前的数据被系统观察到。基于Watermark的类型，完美或启发式，这个假设分别可能是硬性保证或是有根据的猜测：

* 完美的Watermarks：这种场景下，我们确切地认识输入源时，我们有可能构建完美的Watermark；在这种场景下，不可能有迟到的数据，所有数据都是提前到或准点到达。
* 启发式的Watermarks：对于许多分布式输入源来说，对数据源确切的全方位的了解是不现实的，在这种场景下次优解就是提供一个启发式的Watermark。启发式的Watermark利用全部可用的关于输入源的信息（partitions，partitions中信息的顺序性，文件的增长率等）去尽可能推断一个大概的进展。在很多情况下，这种Watermark可能会难以置信得准确。即使这样，启发式意味着有时会出错，此时就导致出现了迟到的数据。我们将会在接下来的Trigger章节学习多种处理迟到数据的机制。

Watermarks是一个迷人而复杂的话题，它可以讲上几天几夜，然而此处篇幅有限，所有更多关于它的话题只能等未来的博文讲解。现在，为了更好地理解Watermarks扮演的角色和它的一些短板，我们来看看两个流处理引擎仅仅使用Watermarks去判断流水线中窗口何时发出输出的例子。

![drawback-of-watermark](https://d3ansictanv2wj.cloudfront.net/Figure-06-815-0f83ddead9f4ea13116631e1fb17ad51.png)

在所有两个例子中，窗口都在Watermark传递到窗口末尾时发出输出。这两个处理流程的主要区别在于右边启发式的Watermarks算法没能统计到数值9，这个数值严重地改变了Watermark的走向。这两个例子阐述了Watermarks（和任何其他完整性的标记）的短板，准确地讲它们是：

* 太慢：当Watermark因为处理队列中其他待处理的数据（比如日志输入被网络带宽限制）被阻塞的时候，那么如果仅仅依靠Watermark去判断进度的话，输出就会滞后。

    就像上面左图中比较晚到达的数值9很明显地拖了后续所有窗口的后腿，即便后续的窗口内的输入都已完整。这个现象在窗口2 [12:02,12:04) 中非常明显，从该窗口从接受到第一个数值到最终输出结果大约花费了7分钟时间。然而启发性Watermark在这个问题上就相对来说就表现得比较好(大约花费了5分钟)，但是千万别想当然认为启发式Watermark就没有这个问题；上面例子只不过是我故意让窗口忽略数值9地结果而已。
    
    重点就是：当Watermark作为完整性的一个重要标志的时候，依赖完整的输入产生输出的做法从需要低延时的角度上并不可取。比如一个展示关键指标的大盘，时间窗为1小时或1天。你不会想要等整整1小时或1天才能看到大盘上的数据。这就是为什么这样的系统不使用传统批处理的一个蛋疼的原因。反而，不断根据时间推移修正结果直至产生最终结果的方式就好多了。
* 太快：当启发式Watermark错误地过早到达时，可能还有很多有效数据尚未到达，从而产生了迟到数据。这就是例子中右图展示的那样：Watermark在窗口1中数据全部到达前就已经到达了，导致窗口错误地输出了5而不是正确的14。这是启发式Watermark不可避免的天性导致的，启发式的本质就是有时候会出错。所以，仅仅依赖它们去决定何时输出结果在你非常关心正确性时是不够的。

在Streawming 101中，我明确表达了完整性标志对于一个输入为无界数据的健壮的乱序处理系统是不够的这个论点。Watermark的上述两个缺陷：太慢与太快，就是这个论点的论据。你不能仅仅通过完整性标志打造一个兼具正确性与低延时的系统。然而就是Triggers解决了Watermarks的这些缺陷。

When：Triggers最棒的地方在于Triggers真特么就是太棒了！

Triggers就是“When in processing time are results materialized?”这个问题的后一半解答。Triggers申明了处理时间中何时窗口应该发送输出（其实Trigger本身也能够根据业务时间判断，比如依赖Watermarks）。任何窗口的一次输出被叫做一个窗格。

触发Trigger的信号包含：
* Watermark的推进（也就是业务时间的推进）：也就是我们在图6中看到的例子：当Watermark达到窗口尾部时，窗口的输出被发送。另一个例子是当时间窗口过期时，触发垃圾回收，我们将在之后重新回顾这个例子。
* 处理时间的推进：这在按一定的时间间隔更新数据时非常有用，因为处理时间不像业务时间，是稳定而无延时的。
* 元素数据：在接收到一定数量的元素就触发的场景非常有用。
* 特定符号标志：这个场景下，Trigger的触发依赖一个特定的符号数据（比如一次flush中的EOF标志）。

除了这个简单的依赖具体信号的Triggers，也存在相对复杂的触发逻辑，包括：
* Repetitions（重复）：在配合按处理时间按一定时间间隔更新时有奇效。
* Conjunctions（逻辑AND）：当所有子Triggers被触发时才触发（例如在收到Watermark并且收到一个特定的符号标志的情况下才触发）。
* Disjunctions（逻辑OR），当任意子Triggers被触发时就触发（例如在收到Watermark或者收到一个特定的符号标志的情况下就触发）。
* Sequences（顺序性）：当子Triggers按特定顺序被触发时才触发。
